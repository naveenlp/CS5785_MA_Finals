{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern u'library.ipynb' matched no files\n",
      "This application is used to convert notebook files (*.ipynb) to various other\n",
      "formats.\n",
      "\n",
      "WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
      "\n",
      "Options\n",
      "-------\n",
      "\n",
      "Arguments that take values are actually convenience aliases to full\n",
      "Configurables, whose aliases are listed on the help line. For more information\n",
      "on full configurables, see '--help-all'.\n",
      "\n",
      "--init\n",
      "    Initialize profile with default config files.  This is equivalent\n",
      "    to running `ipython profile create <profile>` prior to startup.\n",
      "--execute\n",
      "    Execute the notebook prior to export.\n",
      "--stdout\n",
      "    Write notebook output to stdout instead of files.\n",
      "--debug\n",
      "    set log level to logging.DEBUG (maximize logging output)\n",
      "--quiet\n",
      "    set log level to logging.CRITICAL (minimize logging output)\n",
      "--inplace\n",
      "    Run nbconvert in place, overwriting the existing notebook (only \n",
      "    relevant when converting to notebook format)\n",
      "--profile=<Unicode> (BaseIPythonApplication.profile)\n",
      "    Default: u'default'\n",
      "    The IPython profile to use.\n",
      "--reveal-prefix=<Unicode> (RevealHelpPreprocessor.url_prefix)\n",
      "    Default: 'reveal.js'\n",
      "    The URL prefix for reveal.js. This can be a a relative URL for a local copy\n",
      "    of reveal.js, or point to a CDN.\n",
      "    For speaker notes to work, a local reveal.js prefix must be used.\n",
      "--ipython-dir=<Unicode> (BaseIPythonApplication.ipython_dir)\n",
      "    Default: u''\n",
      "    The name of the IPython directory. This directory is used for logging\n",
      "    configuration (through profiles), history storage, etc. The default is\n",
      "    usually $HOME/.ipython. This option can also be specified through the\n",
      "    environment variable IPYTHONDIR.\n",
      "--nbformat=<Enum> (NotebookExporter.nbformat_version)\n",
      "    Default: 4\n",
      "    Choices: [1, 2, 3, 4]\n",
      "    The nbformat version to write. Use this to downgrade notebooks.\n",
      "--writer=<DottedObjectName> (NbConvertApp.writer_class)\n",
      "    Default: 'FilesWriter'\n",
      "    Writer class used to write the  results of the conversion\n",
      "--log-level=<Enum> (Application.log_level)\n",
      "    Default: 30\n",
      "    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\n",
      "    Set the log level by value or name.\n",
      "--to=<CaselessStrEnum> (NbConvertApp.export_format)\n",
      "    Default: 'html'\n",
      "    Choices: ['custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides']\n",
      "    The export format to be used.\n",
      "--template=<Unicode> (TemplateExporter.template_file)\n",
      "    Default: u'default'\n",
      "    Name of the template file to use\n",
      "--output=<Unicode> (NbConvertApp.output_base)\n",
      "    Default: ''\n",
      "    overwrite base name use for output files. can only be used when converting\n",
      "    one notebook at a time.\n",
      "--post=<DottedOrNone> (NbConvertApp.postprocessor_class)\n",
      "    Default: u''\n",
      "    PostProcessor class used to write the  results of the conversion\n",
      "--config=<Unicode> (BaseIPythonApplication.extra_config_file)\n",
      "    Default: u''\n",
      "    Path to an extra config file to load.\n",
      "    If specified, load this config file in addition to any other IPython config.\n",
      "--profile-dir=<Unicode> (ProfileDir.location)\n",
      "    Default: u''\n",
      "    Set the profile location directly. This overrides the logic used by the\n",
      "    `profile` option.\n",
      "\n",
      "To see all available configurables, use `--help-all`\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "    The simplest way to use nbconvert is\n",
      "    \n",
      "    > ipython nbconvert mynotebook.ipynb\n",
      "    \n",
      "    which will convert mynotebook.ipynb to the default format (probably HTML).\n",
      "    \n",
      "    You can specify the export format with `--to`.\n",
      "    Options include ['custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides']\n",
      "    \n",
      "    > ipython nbconvert --to latex mynotebook.ipynb\n",
      "    \n",
      "    Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
      "    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
      "    can specify the flavor of the format used.\n",
      "    \n",
      "    > ipython nbconvert --to html --template basic mynotebook.ipynb\n",
      "    \n",
      "    You can also pipe the output to stdout, rather than a file\n",
      "    \n",
      "    > ipython nbconvert mynotebook.ipynb --stdout\n",
      "    \n",
      "    PDF is generated via latex\n",
      "    \n",
      "    > ipython nbconvert mynotebook.ipynb --to pdf\n",
      "    \n",
      "    You can get (and serve) a Reveal.js-powered slideshow\n",
      "    \n",
      "    > ipython nbconvert myslides.ipynb --to slides --post serve\n",
      "    \n",
      "    Multiple notebooks can be given at the command line in a couple of \n",
      "    different ways:\n",
      "    \n",
      "    > ipython nbconvert notebook*.ipynb\n",
      "    > ipython nbconvert notebook1.ipynb notebook2.ipynb\n",
      "    \n",
      "    or you can specify the notebooks list in a config file, containing::\n",
      "    \n",
      "        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
      "    \n",
      "    > ipython nbconvert --config mycfg.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run \"../library.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.lda import LDA\n",
    "from sklearn import svm, cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import linear_model, svm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400,) (600,) 3000\n"
     ]
    }
   ],
   "source": [
    "train_indices, test_indices = [], []\n",
    "for train_index, test_index in KFold(len(train_cnn), n_folds=5):\n",
    "    train_indices = train_index\n",
    "    test_indices = test_index\n",
    "y_train, y_test = train_labels[train_indices], train_labels[test_indices]\n",
    "print train_indices.shape, test_indices.shape, len(train_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.373333333333\n"
     ]
    }
   ],
   "source": [
    "train_cnn_normalized = preprocessing.scale(train_cnn, axis=1)\n",
    "predictions_cnn, svmmodel_cnn, score_cnn = 0, 0, 0\n",
    "\n",
    "x_train_cnn, x_test_cnn = train_cnn_normalized[train_indices], train_cnn_normalized[test_indices]\n",
    "\n",
    "svmmodel_cnn = svm.SVC(kernel='linear', probability=True).fit(x_train_cnn,y_train) \n",
    "score_cnn = svmmodel_cnn.score(x_test_cnn,y_test) \n",
    "predictions_cnn = svmmodel_cnn.predict_proba(x_test_cnn) \n",
    "print score_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weighted predictions\n",
    "weight_cnn = 0.496763484\n",
    "weighted_predictions_cnn = weight_cnn*np.array(predictions_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115\n"
     ]
    }
   ],
   "source": [
    "train_bow_normalized = preprocessing.scale(train_bow, axis=0)\n",
    "predictions_bow, svmmodel_bow, score_bow = 0, 0, 0\n",
    "\n",
    "x_train_bow, x_test_bow = train_bow_normalized[train_indices], train_bow_normalized[test_indices]\n",
    "\n",
    "svmmodel_bow = svm.SVC(kernel='linear', probability=True).fit(x_train_bow,y_train) \n",
    "score_bow = svmmodel_bow.score(x_test_bow,y_test) \n",
    "predictions_bow = svmmodel_bow.predict_proba(x_test_bow) \n",
    "print score_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weighted predictions\n",
    "weight_bow = 0.167026471\n",
    "weighted_predictions_bow = weight_bow*np.array(predictions_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATTRIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.265\n"
     ]
    }
   ],
   "source": [
    "train_attribs_normalized = preprocessing.scale(train_attribs, axis=1)\n",
    "predictions_attribs, svmmodel_attribs, score_attribs = 0, 0, 0\n",
    "\n",
    "x_train_attribs, x_test_attribs = train_attribs_normalized[train_indices], train_attribs_normalized[test_indices]\n",
    "\n",
    "svmmodel_attribs = svm.SVC(kernel='linear', probability=True).fit(x_train_attribs,y_train) \n",
    "score_attribs = svmmodel_attribs.score(x_test_attribs,y_test) \n",
    "predictions_attribs = svmmodel_attribs.predict_proba(x_test_attribs) \n",
    "print score_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weighted predictions\n",
    "weight_attribs =0.336210907\n",
    "weighted_predictions_attribs = weight_attribs*np.array(predictions_attribs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(wt):\n",
    "    wt_cnn = wt[0]\n",
    "    wt_bow = wt[1]\n",
    "    wt_attrib = wt[2]\n",
    "    predictions_mean = ( wpred(predictions_cnn_final,wt_cnn) + wpred(predictions_bow_final,wt_bow) + wpred(predictions_attribs_final,wt_attrib) ) / 3.0\n",
    "    max_indices = np.argmax(predictions_mean,axis=1)\n",
    "    predicted_classes = svmmodel_cnn.classes_[max_indices]\n",
    "    score = sum(predicted_classes == y_test)*1.0/len(y_test)\n",
    "    return (1 - score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "x0 = [0.496763484,0.167026471,0.336210907]\n",
    "res = minimize(get_score, x0, method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weighted_predictions_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8733085abd8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mweighted_predictions_cnn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweighted_predictions_bow\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweighted_predictions_attribs\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredicted_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvmmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weighted_predictions_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_mean = ( weighted_predictions_cnn + weighted_predictions_bow + weighted_predictions_attribs ) / 3.0\n",
    "max_indices = np.argmax(predictions_mean,axis=1)\n",
    "predicted_classes = svmmodel_cnn.classes_[max_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-27f85df04a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# overall score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_classes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# overall score\n",
    "sum(predicted_classes == y_test)*1.0/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL DATA AT ONCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.355\n"
     ]
    }
   ],
   "source": [
    "# we use this to understand if it is advantageous to perform the classification \n",
    "# with all data at once in the same featureset\n",
    "train_all = np.hstack([train_cnn, train_bow, train_attribs])\n",
    "train_all_normalized = preprocessing.scale(train_all, axis=0)\n",
    "predictions_all, svmmodel_all, score_all = 0, 0, 0\n",
    "\n",
    "x_train_all, x_test_all = train_all_normalized[train_indices], train_all_normalized[test_indices]\n",
    "\n",
    "svmmodel_all = svm.SVC(kernel='linear', probability=True).fit(x_train_all,y_train) \n",
    "score_all = svmmodel_all.score(x_test_all,y_test) \n",
    "predictions_all = svmmodel_all.predict_proba(x_test_all) \n",
    "print score_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## KAGGLE SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_predictions_for(train_vals, test_vals, train_lbls, axs=1):\n",
    "    train_vals_normalized = preprocessing.scale(train_vals, axis=axs)\n",
    "    predictions_vals, svmmodel = 0, 0\n",
    "\n",
    "    svmmodel = svm.SVC(kernel='linear', probability=True).fit(train_vals,train_lbls) \n",
    "    predictions_vals = svmmodel.predict_proba(test_vals) \n",
    "    return predictions_vals, svmmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_cnn_final, svm_cnn_final = svm_predictions_for(train_cnn, test_cnn, train_labels, axs=1)\n",
    "np.savetxt('predictions_cnn_final.txt', predictions_cnn_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_bow_final, svm_bow_final = svm_predictions_for(train_bow, test_bow, train_labels, axs=0)\n",
    "np.savetxt('predictions_bow_final.txt', predictions_bow_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_attribs_final, svm_attribs_final = svm_predictions_for(train_attribs, test_attribs, train_labels, axs=1)\n",
    "np.savetxt('predictions_attribs_final.txt', predictions_attribs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_cluster = np.loadtxt('predictions_cluster.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0000.jpg' 'soccer_field']\n",
      " ['0001.jpg' 'rubble']\n",
      " ['0002.jpg' 'junk_pile']\n",
      " ..., \n",
      " ['0997.jpg' 'reception']\n",
      " ['0998.jpg' 'cheese_factory']\n",
      " ['0999.jpg' 'pasture']]\n"
     ]
    }
   ],
   "source": [
    "def wpred(predictions, wt):\n",
    "    return wt*np.array(predictions)\n",
    "\n",
    "predictions_mean_final = ( wpred(predictions_cnn_final,0.496763484) + wpred(predictions_bow_final,0.167026471) + wpred(predictions_attribs_final,0.336210907) ) / 3.0\n",
    "max_indices_final = np.argmax(predictions_mean_final,axis=1)\n",
    "predicted_classes_final = svm_cnn_final.classes_[max_indices_final]\n",
    "kaggle_output(predicted_classes_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight calculation\n",
    "weight_for_cluster = 0.291666666667\n",
    "weight_for_cnn = 0.373333333333\n",
    "weight_for_bow = 0.115\n",
    "weight_for_attribs = 0.265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0000.jpg' 'soccer_field']\n",
      " ['0001.jpg' 'rubble']\n",
      " ['0002.jpg' 'junk_pile']\n",
      " ..., \n",
      " ['0997.jpg' 'fastfood_restaurant']\n",
      " ['0998.jpg' 'assembly_line']\n",
      " ['0999.jpg' 'pasture']]\n"
     ]
    }
   ],
   "source": [
    "predictions_mean_final_n = ( wpred(predictions_cnn_final,0.4) + wpred(predictions_bow_final,0.1) + wpred(predictions_cluster,0.3) + wpred(predictions_attribs_final,0.2) )\n",
    "max_indices_final_n = np.argmax(predictions_mean_final_n,axis=1)\n",
    "predicted_classes_final_n = svm_cnn_final.classes_[max_indices_final_n]\n",
    "kaggle_output(predicted_classes_final_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
